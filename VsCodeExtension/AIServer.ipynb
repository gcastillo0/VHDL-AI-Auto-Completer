{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u4yUJRKgW8f",
        "outputId": "42feefac-5ba0-4963-9182-b4e2bc725264"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.2)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n",
            "deb https://ngrok-agent.s3.amazonaws.com buster main\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://ngrok-agent.s3.amazonaws.com buster InRelease [20.3 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,185 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://ngrok-agent.s3.amazonaws.com buster/main amd64 Packages [7,047 B]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,527 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,626 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,224 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,454 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,513 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,738 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [33.8 kB]\n",
            "Fetched 20.7 MB in 7s (2,773 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "59 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  ngrok\n",
            "0 upgraded, 1 newly installed, 0 to remove and 59 not upgraded.\n",
            "Need to get 9,885 kB of archives.\n",
            "After this operation, 0 B of additional disk space will be used.\n",
            "Get:1 https://ngrok-agent.s3.amazonaws.com buster/main amd64 ngrok amd64 3.18.4 [9,885 kB]\n",
            "Fetched 9,885 kB in 1s (16.6 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package ngrok.\n",
            "(Reading database ... 123630 files and directories currently installed.)\n",
            "Preparing to unpack .../ngrok_3.18.4_amd64.deb ...\n",
            "Unpacking ngrok (3.18.4) ...\n",
            "Setting up ngrok (3.18.4) ...\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!pip install flask transformers huggingface_hub pyngrok\n",
        "!curl -sSL https://ngrok-agent.s3.amazonaws.com/ngrok.asc \\\n",
        "\t| sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null \\\n",
        "\t&& echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" \\\n",
        "\t| sudo tee /etc/apt/sources.list.d/ngrok.list \\\n",
        "\t&& sudo apt update \\\n",
        "\t&& sudo apt install ngrok\n",
        "\n",
        "!ngrok config add-authtoken 2pOkYySnSPEfSzC8mmUuYHXRTr0_7eN6ZAq6htCGNcg8sJWU1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0SLvNkYuOdT",
        "outputId": "650eaafb-768e-4655-f1c1-40eb9df8f3ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj7Jkyb_sj5M",
        "outputId": "a6fdc90d-6677-4372-9c0e-f27eca43fb31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flask app is live at NgrokTunnel: \"https://7756-34-125-148-182.ngrok-free.app\" -> \"http://localhost:5004\"\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set up a tunnel to the Flask app\n",
        "public_url = ngrok.connect(5004)\n",
        "print(f\"Flask app is live at {public_url}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uZJ6knhgkMT",
        "outputId": "9e3e77d5-f8c7-467b-ae47-1b9e4ebfb0c8",
        "cellView": "code"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on all addresses (0.0.0.0)\n",
            " * Running on http://127.0.0.1:5004\n",
            " * Running on http://172.28.0.12:5004\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- '}\n",
            "{'input': '-- '}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- '}\n",
            "{'input': '-- '}\n",
            "{'input': '-- '}\n",
            "{'input': '-- '}\n",
            "{'input': '-- '}\n",
            "{'input': '-- '}\n",
            "{'input': '-- '}\n",
            "{'input': '-- '}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- BCD '}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- BCD to '}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:41] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- BCD to 7 '}\n",
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n",
            "\r\n",
            "-- Memoria de la memoria que es sintacional\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:41] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- BCD to 7 segments '}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:49] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:49] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Copyright 2013 Ray Salemi\n",
            "--\n",
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n",
            "  ----------------------------------------------------------------------\n",
            "  Copyright 2013 Ray Salemi\n",
            "--\n",
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:49] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:49] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:50] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:50] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n",
            "  ----------------------------------------------------------------------\n",
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n",
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n",
            "  ----------------------------------------------------------------------\n",
            "  Copyright 2013 Ray Salemi\n",
            "--\n",
            "  For more information about this package:\n",
            "\n",
            "-- This is a workaround to the issue described in issue #5750.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:50] \"POST /generate HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:50] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- BCD to 7 segments\\nlibrary '}\n",
            "  Copyright 2013 Ray Salemi\n",
            "--\n",
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n",
            "\n",
            " (c) Copyright 2012 Xilinx, Inc. All rights reserved.\n",
            " ****************************************************************************\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:51] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "\r\n",
            "--\r\n",
            "\r\n",
            "-- Component declaration\r\n",
            "--\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:51] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ichthyan3\r\n",
            "library IEEE;\r\n",
            "ixj-jal\n",
            "-- (C) by Jose A. Marroquillo\n",
            "\n",
            " FMD controller 1\r\n",
            "--\r\n",
            "-- Design name: \r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:52] \"POST /generate HTTP/1.1\" 200 -\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "-- VHDL BLT to 7\n",
            "\n",
            "library IEEE;\n",
            "\n",
            "--\n",
            "-- Copyright (C) 2010 Tristan Gingold\n",
            "--\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:53] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\n",
            "-- \r\n",
            "-- Copyright (C) 2014 Alvaro Lopes\r\n",
            "\n",
            "\n",
            "library ieee;\n",
            "use ieee.std_logic_1164.all;\n",
            "\r\n",
            "library IEEE;\r\n",
            "use IEEE.STD_LOGIC_1164.ALL;\r\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:16:53] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     IEEE;\n",
            "use      IEEE.STD_LOGIC_1164.ALL;\n",
            " IEEE;\n",
            "use  IEEE.STD_LOGIC_1164.ALL;\n",
            "\n",
            "entity PLL is\n",
            " IEEE;\n",
            "use     IEEE.STD_LOGIC_1164.all;\n",
            "\n",
            "entity BCDto7_Seg is\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- BCD to 7 segments\\nlibrary      IEEE;\\nuse      IEEE.STD_LOGIC_1164.ALL;\\n\\nentity '}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:17:08] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ROTOR is\n",
            "    Port (  CLK          : in  STD_LOGIC;\n",
            "   7seg is\n",
            "    port (\n",
            "        x, y : in  STD_LOGIC_VECTOR(3 downto 0);\n",
            " bcdto7seg is\n",
            "        port (\n",
            "            clk, reset, next_clk : in  STD_LOGIC;\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- BCD to 7 segments\\nlibrary      IEEE;\\nuse      IEEE.STD_LOGIC_1164.ALL;\\n\\nentity  bcdto7seg is\\n        port (\\n            clk, reset: in  STD_LOGIC;\\n            disp:'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': '-- BCD to 7 segments\\nlibrary      IEEE;\\nuse      IEEE.STD_LOGIC_1164.ALL;\\n\\nentity  bcdto7seg is\\n        port (\\n            clk, reset: in  STD_LOGIC;\\n            disp: '}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:17:39] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " in  STD_LOGIC_VECTOR (7 downto 0);\n",
            "            bs: out STD_LOGIC_VECTOR (7 downto 0)\n",
            "        );\n",
            " out STD_LOGIC_VECTOR(7 downto 0)\n",
            "        );\n",
            "end                                       -- bcdto7seg and the corresponding bcdto7seg component\n",
            " inout STD_LOGIC_VECTOR (7 downto 0);\n",
            "            input_in: in STD_LOGIC_VECTOR (7 downto 0);\n",
            "            output: out STD_LOGIC_VECTOR (7 downto 0)\n",
            "        );\n",
            "end entity;\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [03/Dec/2024 17:17:39] \"POST /generate HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " in  STD_LOGIC_VECTOR(7 downto 0);\n",
            "            clk_clk: in  STD_LOGIC\n",
            "        );\n",
            "end       bcdto7seg;\n",
            "\n",
            "architecture Behavioral of bcdto7seg is\n",
            "begin\n",
            " in  STD_LOGIC_VECTOR (7 downto 0);\n",
            "            segments: out STD_LOGIC_VECTOR (7 downto 0)\n",
            "            );\n",
            "end  bcdto7seg;\n",
            "\n",
            "architecture Behavioral of bcdto7seg is\n",
            "     out  STD_LOGIC_VECTOR(7 DOWNTO 0)\n",
            "        );\n",
            "end bcdto7seg;\n",
            "\n",
            "architecture arch of bcdto7seg is\n",
            "begin\n",
            "    disp <= disp + 1;\n",
            "end arch;\n",
            "\n",
            "entity bcdto7seg_bcdto7seg is\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "#For drive model\n",
        "drive_path = '/content/drive/MyDrive/gpt_neo2'\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(drive_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(drive_path)\n",
        "\n",
        "if device == \"cuda\":\n",
        "    model = model.cuda()  # Move to GPU\n",
        "else:\n",
        "    model = model.cpu()   # Ensure it's on the CPU\n",
        "\n",
        "@app.route('/generate', methods=['POST'])\n",
        "def generate():\n",
        "    try:\n",
        "        data = request.json\n",
        "        print(data)\n",
        "        prompt = data.get(\"input\", \"\")\n",
        "\n",
        "        if not prompt:\n",
        "            return jsonify({\"error\": \"No prompt provided\"}), 400\n",
        "\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "        # suggestions = []\n",
        "        # outputs = [model.generate(\n",
        "        #     inputs[\"input_ids\"],\n",
        "        #     max_length=100,\n",
        "        #     num_return_sequences=1,\n",
        "        #     temperature=0.5,\n",
        "        #     do_sample=True,\n",
        "        #     top_p=0.9,\n",
        "        #     pad_token_id=tokenizer.eos_token_id\n",
        "        # ),\n",
        "        # model.generate(\n",
        "        #     inputs[\"input_ids\"],\n",
        "        #     max_length=100,\n",
        "        #     num_return_sequences=1,\n",
        "        #     temperature=0.6,\n",
        "        #     top_k=100,\n",
        "        #     do_sample=True,\n",
        "        #     pad_token_id=tokenizer.eos_token_id\n",
        "        # ),\n",
        "        # model.generate(\n",
        "        #     inputs[\"input_ids\"],\n",
        "        #     max_length=100,\n",
        "        #     num_return_sequences=1,\n",
        "        #     do_sample=True,\n",
        "        #     top_k=100,\n",
        "        #     temperature=0.8,\n",
        "        #     pad_token_id=tokenizer.eos_token_id\n",
        "        # )]\n",
        "        # for output in outputs:\n",
        "        #   for sequence in output:\n",
        "        #     suggestions.append(tokenizer.decode(sequence, skip_special_tokens=True))\n",
        "\n",
        "        # Generate multiple outputs manually\n",
        "        suggestions = []\n",
        "        for _ in range(3):  # Generate three suggestions\n",
        "            output = model.generate(\n",
        "                inputs.input_ids,\n",
        "                max_length=len(prompt)+16,\n",
        "                temperature=0.8,  # Control randomness\n",
        "                top_k=50,         # Limit to top-k tokens\n",
        "                do_sample=True,   # Enable sampling for diversity\n",
        "            )\n",
        "            decoded_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "            formatted_output,_,_ = decoded_output[len(prompt):].rpartition('\\n')\n",
        "            suggestions.append(formatted_output)\n",
        "\n",
        "        # Sort by length (as a proxy for \"accuracy\" or completion suitability)\n",
        "        sorted_suggestions = sorted(set(suggestions), key=lambda x: len(x))  # Remove duplicates\n",
        "        for suggestion in sorted_suggestions:\n",
        "          print(suggestion)\n",
        "        response = jsonify({\"suggestions\": sorted_suggestions})\n",
        "\n",
        "\n",
        "        return response\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"Error during generation:\", e)\n",
        "        return jsonify({\"error\": str(e)}), 500\n",
        "\n",
        "app.run(host='0.0.0.0', port=5004)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}